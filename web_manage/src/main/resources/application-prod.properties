# application
spring.application.name=yoyo-admin
spring.application.version=0.0.1
spring.freemarker.checkTemplateLocation=false
# web
server.port=8081
server.servlet.session.timeout=P1D
server.compression.enabled=true
spring.servlet.multipart.max-file-size=100MB
spring.servlet.multipart.max-request-size=100MB
# Serialization
spring.jackson.locale=zh
spring.jackson.time-zone=GMT+8
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss
# JPA config
spring.jpa.database=MYSQL
spring.jpa.show-sql=true
spring.jpa.open-in-view=true
spring.jpa.hibernate.ddl-auto=update

## druid config
spring.datasource.druid.stat-view-servlet.enabled=true
spring.datasource.druid.stat-view-servlet.login-username=admin
spring.datasource.druid.stat-view-servlet.login-password=123456
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.driver-class-name=com.mysql.cj.jdbc.Driver
# allowMultiQueries=true -> The parameter allows the JDBC connection to perform multiple additions, deletions, and changes at one time. If this parameter is not configured, all batch operations will report errors.
# rewriteBatchedStatements=true -> Mybatis batch execution needs to add parameters
spring.datasource.druid.url=jdbc:mysql://127.0.0.1:3306/yoyodb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8&allowMultiQueries=true&rewriteBatchedStatements=true
spring.datasource.druid.username=yoyo
spring.datasource.druid.password=123456
# Initialize the number of connection pools
spring.datasource.druid.initial-size=5
# Maximum number of connection pools
spring.datasource.druid.max-active=20
# Minimum number of connection pool -- It is no longer used, and the configuration has no effect
spring.datasource.druid.min-idle=5
# Configure the time to wait for a timeout to obtain a connection, in milliseconds. By default, fair locks are enabled, and the concurrency efficiency will decrease.
spring.datasource.druid.max-wait=60000
# Open PSCache and specify the size of PSCache on each connection
spring.datasource.druid.pool-prepared-statements=true
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=20
# The sql used to detect whether the connection is valid requires a query statement.
# If validationQuery is null, testOnBorrow, testOnReturn, testWhileIdle will not work
spring.datasource.druid.validation-query=SELECT 1 FROM DUAL
spring.datasource.druid.validation-query-timeout=30000
# When applying for a connection, execute validationQuery to check whether the connection is valid. This configuration will reduce performance.
spring.datasource.druid.test-on-borrow=false
# When returning the connection, execute the validationQuery to check whether the connection is valid. This configuration will reduce performance.
spring.datasource.druid.test-on-return=false
# It is recommended to configure it to true, which does not affect performance and ensures security.
# Detect when applying for a connection. If the idle time is greater than timeBetweenEvictionRunsMillis, execute validationQuery to check whether the connection is valid.
spring.datasource.druid.test-while-idle=true
# How long is the configuration interval before detection is performed to detect idle connections that need to be closed, in milliseconds
spring.datasource.druid.time-between-eviction-runs-millis=60000
# Configure the minimum lifetime of a connection in the pool, in milliseconds
spring.datasource.druid.min-evictable-idle-time-millis=300000
# Configure extension plug-ins by aliases, separated by commas. Commonly used plug-ins are:
# Monitor statistics -> filter:stat
# Log -> filter:log4j
# Defense against sql injection -> filter:wall
spring.datasource.druid.filters=stat,wall

## swagger settings
settings.swagger.enabled=true
# If this is set to true, the swagger page is hidden
swagger.production=false
# This setting is true to enable account password verification
swagger.basic.enable=true
swagger.basic.username=admin
swagger.basic.password=123456

## elasticsearch config
elasticsearch.host=127.0.0.1
elasticsearch.port=9200
elasticsearch.username=elastic
elasticsearch.password=elasticPassword

## redis config
spring.redis.host=127.0.0.1
spring.redis.port=6379
spring.redis.database=0
spring.redis.password=redisPassword
spring.redis.lettuce.pool.max-active=-1
spring.redis.lettuce.pool.max-wait=-1
spring.redis.lettuce.pool.max-idle=200
spring.redis.lettuce.pool.min-idle=20

## kafka config
spring.kafka.bootstrap-servers=127.0.0.1:9092
# encryption config
# spring.kafka.properties.sasl.mechanism=PLAIN
# spring.kafka.properties.security.protocol=SASL_PLAINTEXT
# spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='your_username' password='your_password';
# default topic config
spring.kafka.template.default-topic=yoyo_admin_topic
# producer config
# number of retries, set a value greater than 0, then the client will resend the records that failed to be sent
spring.kafka.producer.retries=3
# batch size, 16k
spring.kafka.producer.batch-size=16384
# buffer storage, 32m
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.acks=1
# specify the message key and decoding way of the message body
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# consumer config
spring.kafka.consumer.group-id=spring_customer
# whether autocommit (manual submitted to shut down, otherwise an error)
spring.kafka.consumer.enable-auto-commit=false
# consumption offset configuration
# none: If the value of the previous offset is not found for the consumer, that is, the offset is not automatically maintained or the offset is manually maintained, an exception is thrown
# earliest: When there is a submitted offset under each partition: start consumption from the offset; when there is no submitted offset under each partition: start consumption from the beginning
# latest: When there is a submitted offset under each partition: start consumption from the offset; when there is no submitted offset under each partition: start consumption from the latest data
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# listener config
# record: submitted after each record is processed by the consumer listener (ListenerConsumer)
# batch: submitted after each batch of poll() data is processed by ListenerConsumer
# time: Submit when the data of each batch of poll() is processed by ListenerConsumer and the time since the last submission is greater than TIME
# count: Submit when the number of processed records is greater than or equal to COUNT after each batch of poll() data is processed by ListenerConsumer
# count_time: Submit when one of the conditions in TIME or COUNT is met
# manual: After each batch of poll() data is processed by ListenerConsumer, manually call Acknowledgment.acknowledge() and submit
# manual_immediate: Submit immediately after manually calling Acknowledgment.acknowledge(), which is generally recommended
spring.kafka.listener.ack-mode=manual_immediate
# the number of threads running in the listener container.
spring.kafka.listener.concurrency=1

## minio config
minio.endpoint=http://127.0.0.1:9000
minio.port=9000
# Login account
minio.accessKey=your_user
# Login password
minio.secretKey=your_password
minio.secure=false
# Default bucket name
minio.bucket-name=default
# Maximum size of picture file
minio.image-size=10485760
# Maximum file size
minio.file-size=1073741824

## business config
# uploading & downloading setting
settings.files.upload-root-path=/storage/web_code/uploads/
settings.files.download-root-path=/storage/web_code/downloads/
# single-user settings, It is recommended to set it to false during development.
settings.hosts.use-single-user-limit=true
# periodical-task settings
settings.task.enabled=false
# external interface proxy
settings.external.api-url=http://127.0.0.1:5000/external

## JavaMailSender config
# smtp.163.com,smtp.qq.com,(smtp.gmail.com is unavailable)
spring.mail.host=smtp.163.com
spring.mail.username=xxx@163.com
# use authorization code
spring.mail.password=your_authorization_code
spring.mail.port=465
spring.mail.default-encoding=utf-8
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.starttls.required=true
spring.mail.protocol=smtp
spring.mail.properties.mail.smtp.ssl.enable=true
spring.mail.properties.mail.smtp.socketFactory.port=465
spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory
# mail debug
spring.mail.properties.mail.debug=false
# check connectivity at startup
spring.mail.test-connection=false

## aliyun sms config
aliyun.sms.accessKeyId=your_accessKeyId
aliyun.sms.accessKeySecret=your_accessKeySecret
aliyun.sms.domain=dysmsapi.aliyuncs.com
aliyun.sms.resend-interval=60
aliyun.sms.usable-timeout=300
aliyun.sms.signName=your_signName
aliyun.sms.loginTemplate=your_loginTemplate
aliyun.sms.registerTemplate=your_registerTemplate
aliyun.sms.changePasswordTemplate=your_changePasswordTemplate
aliyun.sms.apiVersion=2017-05-25
aliyun.sms.url=http://dysmsapi.aliyuncs.com